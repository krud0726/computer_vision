{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facial_recognition_practice.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XgjYEMBobMz"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzBMOtIgovKX"
      },
      "source": [
        "import face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOFp_IU1pDaV"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTXF3PqJpEqX"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hRRuWekpM5f"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le6JYfQ-piWY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdeFUujvu_h1"
      },
      "source": [
        "# Step1. Register Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro4YIzkVprvf"
      },
      "source": [
        "KNOWN_FACES_DIR = \"/content/drive/MyDrive/people\"\n",
        "UNKNOWN_FACES_DIR = \"/content/drive/MyDrive/unpeople\"\n",
        "TOLERANCE = 0.5\n",
        "\n",
        "FRAME_THICKNESS = 3\n",
        "FONT_THICKNESS = 2\n",
        "MODEL = \"cnn\" # hog\n",
        "\n",
        "known_faces = []\n",
        "known_names = []\n",
        "\n",
        "# 등록하기\n",
        "for name in os.listdir(KNOWN_FACES_DIR):\n",
        "  for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
        "    image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
        "    encoding = face_recognition.face_encodings(image)[0]\n",
        "    known_faces.append(encoding)\n",
        "    known_names.append(name)\n",
        "    print(known_names)\n",
        "    print(known_faces)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLKLWiuG8Lq"
      },
      "source": [
        "# Step2. Face Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo-HWytfuEmI"
      },
      "source": [
        "# 테스트 사진 불러오기 - 해당 얼굴위치에 대한 좌표 인코딩\n",
        "print(\"processing unknown faces\")\n",
        "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
        "  print(filename)\n",
        "  image = face_recognition.load_image_file(f\"{UNKNOWN_FACES_DIR}/{filename}\")\n",
        "  locations = face_recognition.face_locations(image, model= MODEL)\n",
        "  encodings = face_recognition.face_encodings(image, locations)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "  for face_encoding, face_location in zip(encodings, locations):\n",
        "    results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
        "    match = None\n",
        "    if True in results:\n",
        "      match = known_names[results.index(True)]\n",
        "      print(f\"Match found: {match}\")\n",
        "\n",
        "      top_left = (face_location[3], face_location[0])\n",
        "      bottom_right = (face_location[1], face_location[2])\n",
        "\n",
        "      color = [0, 255, 0]\n",
        "      cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
        "\n",
        "      top_left = (face_location[3], face_location[2])\n",
        "      bottom_right = (face_location[1], face_location[2]+22)\n",
        "      cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
        "      cv2.putText(image, match, (face_location[3]+10, face_location[2]+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
        "    cv2_imshow(image)\n",
        "    cv2.waitKey(100000)\n",
        "    #cv2.destroyWindow(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9gkN0167IMw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}